"""
AI Ä°stemci ModÃ¼lÃ¼

Google Gemini API kullanarak persona tabanlÄ± sohbet uygulamasÄ±.
"""

import os
from typing import Optional, Dict, Any
import google.generativeai as genai
from dotenv import load_dotenv

from persona import fetch_persona


# Sabitler
DEFAULT_TEMPERATURE = 0.7
MAX_OUTPUT_TOKENS = 500
GEMINI_MODEL_NAME = "gemini-2.5-flash"

# Ã‡Ä±kÄ±ÅŸ komutlarÄ±
EXIT_COMMANDS = ["exit", "q", "quit"]


class AIClientError(Exception):
    """AI istemci hatalarÄ±nÄ± temsil eder."""
    pass


def load_api_configuration() -> str:
    """
    Ortam deÄŸiÅŸkenlerinden API anahtarÄ±nÄ± yÃ¼kler ve doÄŸrular.
    
    DÃ¶nÃ¼ÅŸ DeÄŸeri:
        str: GeÃ§erli API anahtarÄ±
        
    Hatalar:
        AIClientError: API anahtarÄ± eksik veya geÃ§ersizse
    """
    load_dotenv()
    
    # Geriye dÃ¶nÃ¼k uyumluluk iÃ§in OPENAI_API_KEY kullanÄ±lÄ±yor
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key or "dummy" in api_key.lower():
        raise AIClientError(
            "OPENAI_API_KEY eksik veya geÃ§ersiz. "
            "LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin."
        )
    
    return api_key


def initialize_gemini_model(api_key: str) -> genai.GenerativeModel:
    """
    Gemini AI modelini yapÄ±landÄ±rÄ±r ve baÅŸlatÄ±r.
    
    Parametreler:
        api_key: Google AI API anahtarÄ±
        
    DÃ¶nÃ¼ÅŸ DeÄŸeri:
        GenerativeModel: YapÄ±landÄ±rÄ±lmÄ±ÅŸ Gemini modeli
    """
    genai.configure(api_key=api_key)
    return genai.GenerativeModel(GEMINI_MODEL_NAME)


def load_backend_configuration() -> Dict[str, Optional[str]]:
    """
    Backend panel yapÄ±landÄ±rma deÄŸerlerini ortam deÄŸiÅŸkenlerinden yÃ¼kler.
    
    DÃ¶nÃ¼ÅŸ DeÄŸeri:
        Dict[str, Optional[str]]: Backend yapÄ±landÄ±rma parametreleri
    """
    return {
        "url": os.getenv("BACKEND_PANEL_URL"),
        "token": os.getenv("BACKEND_PANEL_TOKEN"),
        "ably_channel": os.getenv("BACKEND_PANEL_ABLY_CHANNEL"),
        "ably_api_key": os.getenv("BACKEND_PANEL_ABLY_API_KEY")
    }


def load_persona(config: Dict[str, Optional[str]]) -> Optional[Dict[str, Any]]:
    """
    Backend panel'den persona bilgilerini yÃ¼kler.
    
    Parametreler:
        config: Backend yapÄ±landÄ±rma parametreleri
        
    DÃ¶nÃ¼ÅŸ DeÄŸeri:
        Optional[Dict[str, Any]]: Persona verisi veya None
    """
    # Backend panel URL veya Ably kanalÄ± yoksa persona yÃ¼kleme
    if not (config["url"] or config["ably_channel"]):
        return None
    
    try:
        persona = fetch_persona(
            config["url"],
            token=config["token"],
            ably_channel=config["ably_channel"],
            ably_api_key=config["ably_api_key"]
        )
        
        persona_name = persona.get("name") or "(isimsiz)"
        print(f"âœ… Persona backend'den yÃ¼klendi: {persona_name}")
        return persona
        
    except Exception as e:
        print(f"âš ï¸ Persona backend'den yÃ¼klenemedi: {e}")
        return None


def build_persona_prefix(persona: Dict[str, Any]) -> str:
    """
    Persona bilgilerinden prefix string oluÅŸturur.
    
    Parametreler:
        persona: Persona bilgileri
        
    DÃ¶nÃ¼ÅŸ DeÄŸeri:
        str: Persona prefix string'i
    """
    parts = []
    
    if persona.get("name"):
        parts.append(f"Persona adÄ±: {persona.get('name')}")
    
    if persona.get("tone"):
        parts.append(f"Ton: {persona.get('tone')}")
    
    if persona.get("constraints"):
        parts.append(f"KÄ±sÄ±tlamalar: {persona.get('constraints')}")
    
    return " | ".join(parts) if parts else ""


def create_full_prompt(user_prompt: str, persona: Optional[Dict[str, Any]]) -> str:
    """
    KullanÄ±cÄ± prompt'una persona bilgilerini ekler.
    
    Parametreler:
        user_prompt: KullanÄ±cÄ±nÄ±n girdiÄŸi prompt
        persona: Persona bilgileri (opsiyonel)
        
    DÃ¶nÃ¼ÅŸ DeÄŸeri:
        str: Persona bilgileri eklenmiÅŸ tam prompt
    """
    if not persona:
        return user_prompt
    
    persona_prefix = build_persona_prefix(persona)
    
    if persona_prefix:
        return f"{persona_prefix}\n\n{user_prompt}"
    
    return user_prompt


def generate_response(
    model: genai.GenerativeModel,
    prompt: str
) -> Optional[str]:
    """
    AI modelinden yanÄ±t oluÅŸturur.
    
    Parametreler:
        model: Gemini AI modeli
        prompt: GÃ¶nderilecek prompt
        
    DÃ¶nÃ¼ÅŸ DeÄŸeri:
        Optional[str]: Model yanÄ±tÄ± veya None
    """
    response = model.generate_content(
        prompt,
        generation_config={
            "temperature": DEFAULT_TEMPERATURE,
            "max_output_tokens": MAX_OUTPUT_TOKENS,
        }
    )
    
    if response and response.text:
        return response.text.strip()
    
    return None


def display_response(response: Optional[str]) -> None:
    """
    Model yanÄ±tÄ±nÄ± formatlÄ± ÅŸekilde ekrana yazdÄ±rÄ±r.
    
    Parametreler:
        response: GÃ¶sterilecek yanÄ±t
    """
    if not response:
        print("âš ï¸ Model boÅŸ bir yanÄ±t dÃ¶ndÃ¼rdÃ¼.")
        return
    
    print("ğŸ¤– YanÄ±t:")
    print("--------------------------------------------------")
    print(response)
    print("--------------------------------------------------\n")


def run_chat_loop(
    model: genai.GenerativeModel,
    persona: Optional[Dict[str, Any]]
) -> None:
    """
    Ana sohbet dÃ¶ngÃ¼sÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±r.
    
    Parametreler:
        model: Gemini AI modeli
        persona: Persona bilgileri (opsiyonel)
    """
    print("ğŸ’¬ Sohbeti sonlandÄ±rmak iÃ§in 'exit', 'q' veya 'quit' yazÄ±n.\n")
    
    while True:
        try:
            user_prompt = input("ğŸ§  Prompt: ").strip()
             
            # Ã‡Ä±kÄ±ÅŸ kontrolÃ¼
            if user_prompt.lower() in EXIT_COMMANDS:
                print("ğŸ‘‹ Sohbet sonlandÄ±rÄ±ldÄ±.")
                break
            
            # BoÅŸ prompt kontrolÃ¼
            if not user_prompt:
                print("âš ï¸ LÃ¼tfen geÃ§erli bir prompt girin.")
                continue
            
            # Tam prompt oluÅŸtur (persona ile)
            full_prompt = create_full_prompt(user_prompt, persona)
            
            print("\nâ³ YanÄ±t oluÅŸturuluyor...\n")
            
            # YanÄ±t Ã¼ret ve gÃ¶ster
            response = generate_response(model, full_prompt)
            display_response(response)
            
        except KeyboardInterrupt:
            print("\nğŸ›‘ KullanÄ±cÄ± tarafÄ±ndan durduruldu.")
            break
            
        except Exception as e:
            print(f"âŒ Beklenmeyen hata: {e}\n")


def main() -> None:
    """Ana program giriÅŸ noktasÄ±."""
    try:
        # API anahtarÄ±nÄ± yÃ¼kle ve doÄŸrula
        api_key = load_api_configuration()
        
        # Gemini modelini baÅŸlat
        model = initialize_gemini_model(api_key)
        print("âœ… Gemini istemcisi baÅŸarÄ±yla baÅŸlatÄ±ldÄ±.")
        
        # Backend yapÄ±landÄ±rmasÄ±nÄ± yÃ¼kle
        backend_config = load_backend_configuration()
        
        # Persona'yÄ± yÃ¼kle (varsa)
        persona = load_persona(backend_config)
        
        # Sohbet dÃ¶ngÃ¼sÃ¼nÃ¼ baÅŸlat
        run_chat_loop(model, persona)
        
    except AIClientError as e:
        print(f"ğŸš¨ HATA: {e}")
        exit(1)
        
    except Exception as e:
        print(f"ğŸš¨ Beklenmeyen Hata: {e}")
        exit(1)


if __name__ == "__main__":
    main()
